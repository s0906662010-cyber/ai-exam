<!doctype html>
<html lang="zh-Hant">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>ExamVision â€” ç›£è€ƒå‹•ä½œåˆ†æ Demo</title>
  <style>
    body { font-family: -apple-system, "Segoe UI", Roboto, "Noto Sans TC", sans-serif; padding: 12px; background:#f7f9fc; text-align:center; }
    header { margin-bottom:8px; }
    video, canvas { width: 100%; max-width:480px; border:1px solid #ddd; border-radius:8px; display:block; margin:10px auto; background:black; }
    #controls { max-width:480px; margin:8px auto; display:flex; gap:8px; justify-content:center; flex-wrap:wrap; }
    button, select { padding:10px 12px; border-radius:8px; border: none; background:#0078ff; color:white; font-weight:600; cursor:pointer; }
    button:disabled { opacity:0.6; cursor:not-allowed; }
    #log { width:100%; max-width:480px; margin:10px auto; text-align:left; background:white; padding:8px; border-radius:6px; box-shadow:0 1px 3px rgba(0,0,0,0.04); min-height:60px;}
  </style>

  <!-- MediaPipe CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
</head>
<body>
  <header>
    <h1>å¼Šå¼Šåœ¨ç›® â€” è€ƒè©¦ç›£æ¸¬åšå¼Šç‡åˆ†æç³»çµ±</h1>
    <p>æŒ‰ã€Œé–‹å§‹ç›£æ¸¬ã€å¾Œç³»çµ±æœƒæ¯ 5 ç§’åˆ†æä¸€æ¬¡å‹•ä½œï¼ˆç¤ºç¯„ç”¨é€”ï¼‰</p>
  </header>

  <video id="video" playsinline autoplay muted></video>
  <canvas id="overlay"></canvas>

  <div id="cameraStatus" style="margin:10px; font-weight:bold;">ğŸ“· è¼‰å…¥ä¸­...</div>

  <div id="controls">
    <label for="cameraSelect" style="align-self:center; color:#333;">é¡é ­ï¼š</label>
    <select id="cameraSelect"></select>
    <button id="switchBtn">åˆ‡æ›é¡é ­</button>
    <button id="monitorBtn">é–‹å§‹ç›£æ¸¬</button>
  </div>

  <div id="log">ç‹€æ…‹ï¼šå°šæœªå•Ÿå‹•</div>

<script>
(async () => {
  await navigator.mediaDevices.getUserMedia({ video: true }); // å…ˆè«‹æ±‚æ¬Šé™

  const video = document.getElementById('video');
  const cameraSelect = document.getElementById('cameraSelect');
  const switchBtn = document.getElementById('switchBtn');
  const monitorBtn = document.getElementById('monitorBtn');
  const logEl = document.getElementById('log');
  const statusEl = document.getElementById('cameraStatus');

  let currentStream = null;
  let devices = [];
  let currentDeviceId = null;
  let monitorTimer = null;
  let monitoring = false;

  function log(msg) {
    logEl.innerHTML = msg;
  }

  function stopStream() {
    if (currentStream) {
      currentStream.getTracks().forEach(t => t.stop());
      currentStream = null;
    }
  }

  async function startCamera(deviceId) {
    try {
      stopStream();
      currentStream = await navigator.mediaDevices.getUserMedia({
        video: { deviceId: { exact: deviceId } },
      });
      video.srcObject = currentStream;

      const selectedText = cameraSelect.options[cameraSelect.selectedIndex]?.textContent || 'æœªçŸ¥';
      statusEl.textContent = `ğŸ“· ç›®å‰ä½¿ç”¨ï¼š${selectedText}`;
    } catch (err) {
      log('âŒ é–‹å•Ÿé¡é ­å¤±æ•—ï¼š' + err.message);
    }
  }

  // === é¡é ­è¼‰å…¥ï¼ˆä»è®€å–å…¨éƒ¨ï¼Œä½†åªé¡¯ç¤ºå‰å¾Œï¼‰ ===
  async function loadCameras() {
    const allDevices = await navigator.mediaDevices.enumerateDevices();
    const allVideoDevices = allDevices.filter(d => d.kind === 'videoinput');
    devices = allVideoDevices; // ä»è¨˜éŒ„å…¨éƒ¨é¡é ­

    const frontCam = allVideoDevices.find(d => 
      d.label.toLowerCase().includes('front') || 
      d.label.toLowerCase().includes('user') || 
      d.label.includes('å‰')
    );
    const backCam = allVideoDevices.find(d => 
      d.label.toLowerCase().includes('back') || 
      d.label.toLowerCase().includes('rear') || 
      d.label.includes('å¾Œ')
    );

    cameraSelect.innerHTML = '';

    if (backCam) {
      const option = document.createElement('option');
      option.value = backCam.deviceId;
      option.textContent = 'å¾Œé¡é ­';
      cameraSelect.appendChild(option);
    }

    if (frontCam) {
      const option = document.createElement('option');
      option.value = frontCam.deviceId;
      option.textContent = 'å‰é¡é ­';
      cameraSelect.appendChild(option);
    }

    // å¦‚æœæ²’æœ‰æ¨™ç±¤å‰‡è‡³å°‘é¡¯ç¤ºä¸€å€‹
    if (!cameraSelect.options.length && allVideoDevices.length > 0) {
      const option = document.createElement('option');
      option.value = allVideoDevices[0].deviceId;
      option.textContent = 'é è¨­é¡é ­';
      cameraSelect.appendChild(option);
    }

    // å•Ÿå‹•é è¨­é¡é ­
    const defaultDevice = backCam || frontCam || allVideoDevices[0];
    if (defaultDevice) {
      currentDeviceId = defaultDevice.deviceId;
      cameraSelect.value = currentDeviceId;
      await startCamera(currentDeviceId);
      log(`ğŸ¥ å·²å•Ÿå‹•é è¨­é¡é ­ï¼š${cameraSelect.selectedOptions[0].textContent}`);
    } else {
      log('âš ï¸ æ‰¾ä¸åˆ°é¡é ­');
    }
  }

  // === åˆ‡æ›é¡é ­ ===
  switchBtn.addEventListener('click', async () => {
    const options = cameraSelect.options;
    if (options.length <= 1) return;

    const currentIndex = Array.from(options).findIndex(o => o.value === currentDeviceId);
    const nextIndex = (currentIndex + 1) % options.length;
    currentDeviceId = options[nextIndex].value;
    cameraSelect.value = currentDeviceId;
    await startCamera(currentDeviceId);
    log(`ğŸ”„ å·²åˆ‡æ›é¡é ­ï¼š${cameraSelect.selectedOptions[0].textContent}`);
  });

  cameraSelect.addEventListener('change', async () => {
    currentDeviceId = cameraSelect.value;
    await startCamera(currentDeviceId);
    log(`ğŸ”„ å·²åˆ‡æ›é¡é ­ï¼š${cameraSelect.selectedOptions[0].textContent}`);
  });

  // === é‹ç®—åˆ†æ ===
  async function analyzeFrame() {
  const canvas = document.createElement('canvas');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  const dataUrl = canvas.toDataURL('image/jpeg');

  const res = await fetch("https://ai-exam-hl4n.onrender.com/analyze", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ image: dataUrl })
  });

  const result = await res.json();
  if (result.error) {
    log("âŒ " + result.error);
    return;
  }

  const percent = Math.round(result.score * 100);
  const risk = percent < 20 ? 'ğŸŸ¢ å®‰å…¨' :
               percent < 60 ? 'ğŸŸ¡ å¯ç–‘' : 'ğŸ”´ é«˜é¢¨éšª';
  log(`ğŸ“Š åšå¼Šæ©Ÿç‡ï¼šç´„ ${percent}%ã€€â†’ã€€${risk}<br>${result.reasons.join("ã€")}`);
}


  // === é–‹å§‹/åœæ­¢ç›£æ¸¬ ===
  monitorBtn.addEventListener('click', () => {
    if (!monitoring) {
      monitoring = true;
      monitorBtn.textContent = 'åœæ­¢ç›£æ¸¬';
      log('â³ é–‹å§‹ç›£æ¸¬ä¸­ï¼Œæ¯ 5 ç§’åˆ†æä¸€æ¬¡...');
      monitorTimer = setInterval(analyzeFrame, 5000);
      analyzeFrame();
    } else {
      monitoring = false;
      clearInterval(monitorTimer);
      monitorBtn.textContent = 'é–‹å§‹ç›£æ¸¬';
      log('ğŸ›‘ å·²åœæ­¢ç›£æ¸¬ã€‚');
    }
  });

  // åˆå§‹åŒ–é¡é ­
  await loadCameras();
})();
</script>
</body>
</html>
